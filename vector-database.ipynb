{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/alexp/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from datetime import datetime\n",
    "import transformers\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer,BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training,LoraConfig,PeftModel,get_peft_model\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm   \n",
    "import re\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.42s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "model_path = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "# Quantization configuration\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "     #bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Loading the model and tokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path,quantization_config=bnb_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    model_max_length=512,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3052"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"movies_plot.csv\", na_filter=True)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "data['id'] = pd.to_numeric(data['id'], errors='coerce')\n",
    "data['popularity'] = pd.to_numeric(data['popularity'], errors='coerce')\n",
    "data['cast'] = data['cast'].apply(literal_eval)\n",
    "data['crew'] = data['crew'].apply(literal_eval)\n",
    "data['genres'] = data['genres'].apply(literal_eval)\n",
    "data['keywords'] = data['keywords'].apply(literal_eval)\n",
    "data['belongs_to_collection'] = data['belongs_to_collection'].fillna('{}')\n",
    "data['belongs_to_collection'].apply(literal_eval)\n",
    "data['id'] = pd.to_numeric(data['id'], errors='coerce')\n",
    "data['popularity'] = pd.to_numeric(data['popularity'], errors='coerce')\n",
    "\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 500\n",
    "data = data[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 4096\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "X = np.random.random((6863, dim)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentences(paragraph):\n",
    "    # Regular expression to split by sentence-ending punctuation\n",
    "    sentences = re.split(r'(?<=[.!?]) +', paragraph.strip())\n",
    "    return sentences\n",
    "\n",
    "def get_embeddings(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "\n",
    "    hidden_states = outputs.hidden_states[-1]  # Last layer's hidden state\n",
    "    sentence_embedding = hidden_states.mean(dim=1)\n",
    "        \n",
    "    return sentence_embedding\n",
    "\n",
    "def search_similar(query, model, tokenizer, index, metadata, top_k=5):\n",
    "    query_embedding = get_embeddings(query, model, tokenizer)\n",
    "    query_embedding = np.array(query_embedding.cpu().numpy()).astype('float32')\n",
    "    D, I = index.search(query_embedding, top_k)\n",
    "    results = I\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [09:19,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata length: 6863\n",
      "Index length: 6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metadata = []\n",
    "\n",
    "for i, row in tqdm(data.iterrows()):\n",
    "    text = row['overview'] + \" \" + row['plot']\n",
    "    sentences = split_into_sentences(text)\n",
    "    embeddings = np.array([get_embeddings(sentence, model, tokenizer).cpu().numpy() for sentence in sentences])\n",
    "    embeddings = embeddings.astype('float32')\n",
    "    embeddings = embeddings.squeeze(1)\n",
    "    index.add(embeddings)\n",
    "    assert len(embeddings) == len(sentences), \"Mismatch between embeddings and sentences\"\n",
    "    metadata.extend([{\"movie\": row['title'], \"sentence\": embedding} for embedding in embeddings])\n",
    "\n",
    "print(f\"Metadata length: {len(metadata)}\")\n",
    "print(f\"Index length: {index.ntotal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"british spy defeats the bad guys for 100 million dollars\"\n",
    "results = search_similar(query, model, tokenizer, index, data, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1: Hot Shots! Part Deux\n",
      "Result 1: [-0.8022461  -1.5185547  -0.7216797  ... -1.1992188  -0.35253906\n",
      " -0.02400208]\n",
      "\n",
      "Result 2: Austin Powers: International Man of Mystery\n",
      "Result 2: [-0.11749268 -1.0048828   0.43603516 ... -0.9995117   0.43676758\n",
      "  0.66748047]\n",
      "\n",
      "Result 3: L.A. Confidential\n",
      "Result 3: [-0.37280273 -1.8007812  -0.7709961  ... -0.59472656  0.17785645\n",
      " -0.03057861]\n",
      "\n",
      "Result 4: Cinderella\n",
      "Result 4: [ 0.45629883 -0.28564453  1.0673828  ... -0.3720703   0.0904541\n",
      " -0.03695679]\n",
      "\n",
      "Result 5: Fargo\n",
      "Result 5: [-0.12188721 -0.31298828 -1.0263672  ... -0.18469238  0.01383209\n",
      "  0.9194336 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadata[results[0][1]]\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Result {i+1}: {metadata[results[0][i]]['movie']}\")\n",
    "    print(f\"Result {i+1}: {metadata[results[0][i]]['sentence']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here\\'s a detailed plot summary of Austin Powers: International Man of Mystery:\\n\\nThe movie opens with a flashback to 1967, where we see Austin Powers (Mike Myers), a charismatic and confident British spy, in the midst of a high-stakes battle against his arch-nemesis, Dr. Evil (also Mike Myers). In the heat of the moment, Austin is cryogenically frozen by Dr. Evil as part of a trap to prevent him from stopping the villain\\'s plans.\\n\\nFast-forward to 1997, where we see Austin thawed out and released back into the world, still sporting his groovy \\'60s fashion sense and attitude. At first, he struggles to adapt to the modern world, but soon realizes that Dr. Evil has not only survived but has also thawed himself out of cryogenic stasis.\\n\\nDr. Evil reveals that he has been planning a dastardly scheme to hold the world hostage for 100 million dollars, using his latest doomsday device: a giant laser beam capable of destroying an entire city. Austin Powers knows that he must stop Dr. Evil at all costs, but first, he needs to get back into shape.\\n\\nAustin meets Vanessa Kensington (Elizabeth Hurley), a seductive and intelligent British agent who is tasked with helping Austin get the job done. Together, they embark on a series of wild adventures, including a high-speed chase through the streets of London, a run-in with a group of British police officers, and a visit to Dr. Evil\\'s secret lair.\\n\\nAs Austin navigates this new world, he must also contend with his own personal demons. His boss, Basil Exposition (Michael York), puts him in therapy sessions with a Dr. Feldman (Mimi Rogers) who tries to help him adjust to the modern era and control his more outrageous tendencies.\\n\\nThroughout their mission, Austin and Vanessa encounter a series of wacky allies and enemies, including Mini-Me (Seth Green), Dr. Evil\\'s diminutive clone sidekick. The stakes are raised when Dr. Evil unleashes his latest plan: a massive missile capable of destroying an entire city.\\n\\nIn the climactic final confrontation, Austin Powers faces off against Dr. Evil in a battle of wits and fists. With the help of Vanessa and some well-timed judo moves, Austin manages to thwart Dr. Evil\\'s plans and save the world from destruction.\\n\\nThe movie ends with a comedic twist: Austin is reunited with his lost love, Felicity Shagwell (Heather Graham), who appears in a post-credits scene dancing seductively to \"Yeah Baby.\" The scene is a nod to the film\\'s lighthearted tone and comedic irreverence.'"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[342]['plot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:59,  8.38it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, text in tqdm(enumerate(data['plot'])):\n",
    "    X[i] = np.array(get_embeddings(text, model, tokenizer).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(X)\n",
    "faiss.write_index(index, \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[313], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m movie \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAndy heads off to Cowboy Camp, leaving his toy Woody (Tom Hanks)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m movie \u001b[38;5;241m=\u001b[39m tokenizer(movie, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 3\u001b[0m embedding1 \u001b[38;5;241m=\u001b[39m \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmovie\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      4\u001b[0m D, I \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39msearch(np\u001b[38;5;241m.\u001b[39marray(embedding1)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      5\u001b[0m best_matches \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[I[\u001b[38;5;241m0\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[304], line 7\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(text, model, tokenizer)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embeddings\u001b[39m(text, model, tokenizer):\n\u001b[0;32m----> 7\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     10\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/python310/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3055\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3053\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   3054\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 3055\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3057\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/miniconda3/envs/python310/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3114\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 3114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3116\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3117\u001b[0m     )\n\u001b[1;32m   3119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   3120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3121\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3123\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "movie = \"Andy heads off to Cowboy Camp, leaving his toy Woody (Tom Hanks)\"\n",
    "movie = tokenizer(movie, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "embedding1 = get_embeddings(movie, model, tokenizer).cpu().numpy()\n",
    "D, I = index.search(np.array(embedding1).astype('float32'), 5)\n",
    "best_matches = data.iloc[I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>keywords</th>\n",
       "      <th>textual_representation</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862.0</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>21.946943</td>\n",
       "      <td>/rhIRbceoE9lR4veEXuwCC2wARtG.jpg</td>\n",
       "      <td>[{'name': 'Pixar Animation Studios', 'id': 3}]</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>[Tom Hanks, Tim Allen, Don Rickles, Jim Varney...</td>\n",
       "      <td>[John Lasseter, Joss Whedon, Andrew Stanton, J...</td>\n",
       "      <td>[jealousy, toy, boy, friendship, friends, riva...</td>\n",
       "      <td>[TITLE] Toy Story [TAGLINE] nan [OVERVIEW] Led...</td>\n",
       "      <td>Here's a detailed summary of the plot of Toy S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>40000000</td>\n",
       "      <td>[Comedy, Adventure, Fantasy, Science Fiction, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11551.0</td>\n",
       "      <td>tt0122718</td>\n",
       "      <td>en</td>\n",
       "      <td>Small Soldiers</td>\n",
       "      <td>When missile technology is used to enhance toy...</td>\n",
       "      <td>10.039360</td>\n",
       "      <td>/l5laJWvcxgkoqC3nRPs9N5u55jR.jpg</td>\n",
       "      <td>[{'name': 'Universal Pictures', 'id': 33}, {'n...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>1998-07-10</td>\n",
       "      <td>54682547.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>The few, the proud, and the small.</td>\n",
       "      <td>Small Soldiers</td>\n",
       "      <td>False</td>\n",
       "      <td>6.2</td>\n",
       "      <td>522.0</td>\n",
       "      <td>[Gregory Smith, Kirsten Dunst, Denis Leary, Ph...</td>\n",
       "      <td>[Ted Elliott, Terry Rossio, Denise Chamian, Co...</td>\n",
       "      <td>[defense industry, toy shop, technical toy, so...</td>\n",
       "      <td>[TITLE] Small Soldiers [TAGLINE] The few, the ...</td>\n",
       "      <td>Here's a detailed plot summary of the movie Sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 72119, 'name': 'Honey, I Shrunk the Kid...</td>\n",
       "      <td>32000000</td>\n",
       "      <td>[Adventure, Comedy, Family, Science Fiction]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9354.0</td>\n",
       "      <td>tt0097523</td>\n",
       "      <td>en</td>\n",
       "      <td>Honey, I Shrunk the Kids</td>\n",
       "      <td>The scientist father of a teenage girl and boy...</td>\n",
       "      <td>12.358786</td>\n",
       "      <td>/f5eFxKYAd7hN1BxYzBg9qL1SDRe.jpg</td>\n",
       "      <td>[{'name': 'Buena Vista', 'id': 32}]</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>1989-06-22</td>\n",
       "      <td>222724172.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The most astonishing, innovative, backyard adv...</td>\n",
       "      <td>Honey, I Shrunk the Kids</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>756.0</td>\n",
       "      <td>[Rick Moranis, Marcia Strassman, Matt Frewer, ...</td>\n",
       "      <td>[James Horner, Hiro Narita, Tom Schulman, Joe ...</td>\n",
       "      <td>[inventor, ant, shrinking, riesen insekten, bi...</td>\n",
       "      <td>[TITLE] Honey, I Shrunk the Kids [TAGLINE] The...</td>\n",
       "      <td>Here's a detailed plot summary of the movie \"H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10455, 'name': \"Child's Play Collection...</td>\n",
       "      <td>13000000</td>\n",
       "      <td>[Thriller, Horror, Action]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11187.0</td>\n",
       "      <td>tt0103956</td>\n",
       "      <td>en</td>\n",
       "      <td>Child's Play 3</td>\n",
       "      <td>It's been eight years since the events in the ...</td>\n",
       "      <td>24.515462</td>\n",
       "      <td>/pDko1kIkrCaHBSfBj7pAJu1Diss.jpg</td>\n",
       "      <td>[{'name': 'Universal Pictures', 'id': 33}]</td>\n",
       "      <td>[{'iso_3166_1': 'GB', 'name': 'United Kingdom'...</td>\n",
       "      <td>1991-08-30</td>\n",
       "      <td>20560255.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[{'iso_639_1': 'cs', 'name': 'Český'}, {'iso_6...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Chucky has a new playmate.</td>\n",
       "      <td>Child's Play 3</td>\n",
       "      <td>False</td>\n",
       "      <td>5.5</td>\n",
       "      <td>274.0</td>\n",
       "      <td>[Justin Whalin, Perrey Reeves, Jeremy Sylvers,...</td>\n",
       "      <td>[John Frazier, John R. Leonetti, David Kirschn...</td>\n",
       "      <td>[recruit, puppet, killer doll, serial killer, ...</td>\n",
       "      <td>[TITLE] Child's Play 3 [TAGLINE] Chucky has a ...</td>\n",
       "      <td>Here's a detailed plot summary of Child's Play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>45000000</td>\n",
       "      <td>[Adventure, Family, Fantasy]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11359.0</td>\n",
       "      <td>tt0113419</td>\n",
       "      <td>en</td>\n",
       "      <td>The Indian in the Cupboard</td>\n",
       "      <td>A nine-year-old boy gets a plastic Indian and ...</td>\n",
       "      <td>10.673296</td>\n",
       "      <td>/l16BtfILyWxYwSqzofL3V1rMSwe.jpg</td>\n",
       "      <td>[{'name': 'Paramount Pictures', 'id': 4}, {'na...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>1995-07-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Indian in the Cupboard</td>\n",
       "      <td>False</td>\n",
       "      <td>5.9</td>\n",
       "      <td>136.0</td>\n",
       "      <td>[Hal Scardino, Litefoot, Lindsay Crouse, Richa...</td>\n",
       "      <td>[Frank Oz, Kathleen Kennedy, Melissa Mathison,...</td>\n",
       "      <td>[cupboard, games, puppet, parallel world, toy ...</td>\n",
       "      <td>[TITLE] The Indian in the Cupboard [TAGLINE] n...</td>\n",
       "      <td>Here's a detailed summary of the plot:\\n\\nThe ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     adult                              belongs_to_collection    budget  \\\n",
       "0    False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "400  False                                                 {}  40000000   \n",
       "450  False  {'id': 72119, 'name': 'Honey, I Shrunk the Kid...  32000000   \n",
       "423  False  {'id': 10455, 'name': \"Child's Play Collection...  13000000   \n",
       "23   False                                                 {}  45000000   \n",
       "\n",
       "                                                genres  \\\n",
       "0                          [Animation, Comedy, Family]   \n",
       "400  [Comedy, Adventure, Fantasy, Science Fiction, ...   \n",
       "450       [Adventure, Comedy, Family, Science Fiction]   \n",
       "423                         [Thriller, Horror, Action]   \n",
       "23                        [Adventure, Family, Fantasy]   \n",
       "\n",
       "                                 homepage       id    imdb_id  \\\n",
       "0    http://toystory.disney.com/toy-story    862.0  tt0114709   \n",
       "400                                   NaN  11551.0  tt0122718   \n",
       "450                                   NaN   9354.0  tt0097523   \n",
       "423                                   NaN  11187.0  tt0103956   \n",
       "23                                    NaN  11359.0  tt0113419   \n",
       "\n",
       "    original_language              original_title  \\\n",
       "0                  en                   Toy Story   \n",
       "400                en              Small Soldiers   \n",
       "450                en    Honey, I Shrunk the Kids   \n",
       "423                en              Child's Play 3   \n",
       "23                 en  The Indian in the Cupboard   \n",
       "\n",
       "                                              overview  popularity  \\\n",
       "0    Led by Woody, Andy's toys live happily in his ...   21.946943   \n",
       "400  When missile technology is used to enhance toy...   10.039360   \n",
       "450  The scientist father of a teenage girl and boy...   12.358786   \n",
       "423  It's been eight years since the events in the ...   24.515462   \n",
       "23   A nine-year-old boy gets a plastic Indian and ...   10.673296   \n",
       "\n",
       "                          poster_path  \\\n",
       "0    /rhIRbceoE9lR4veEXuwCC2wARtG.jpg   \n",
       "400  /l5laJWvcxgkoqC3nRPs9N5u55jR.jpg   \n",
       "450  /f5eFxKYAd7hN1BxYzBg9qL1SDRe.jpg   \n",
       "423  /pDko1kIkrCaHBSfBj7pAJu1Diss.jpg   \n",
       "23   /l16BtfILyWxYwSqzofL3V1rMSwe.jpg   \n",
       "\n",
       "                                  production_companies  \\\n",
       "0       [{'name': 'Pixar Animation Studios', 'id': 3}]   \n",
       "400  [{'name': 'Universal Pictures', 'id': 33}, {'n...   \n",
       "450                [{'name': 'Buena Vista', 'id': 32}]   \n",
       "423         [{'name': 'Universal Pictures', 'id': 33}]   \n",
       "23   [{'name': 'Paramount Pictures', 'id': 4}, {'na...   \n",
       "\n",
       "                                  production_countries release_date  \\\n",
       "0    [{'iso_3166_1': 'US', 'name': 'United States o...   1995-10-30   \n",
       "400  [{'iso_3166_1': 'US', 'name': 'United States o...   1998-07-10   \n",
       "450  [{'iso_3166_1': 'US', 'name': 'United States o...   1989-06-22   \n",
       "423  [{'iso_3166_1': 'GB', 'name': 'United Kingdom'...   1991-08-30   \n",
       "23   [{'iso_3166_1': 'US', 'name': 'United States o...   1995-07-14   \n",
       "\n",
       "         revenue  runtime                                   spoken_languages  \\\n",
       "0    373554033.0     81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "400   54682547.0    110.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "450  222724172.0     93.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "423   20560255.0     90.0  [{'iso_639_1': 'cs', 'name': 'Český'}, {'iso_6...   \n",
       "23           0.0     96.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "       status                                            tagline  \\\n",
       "0    Released                                                NaN   \n",
       "400  Released                 The few, the proud, and the small.   \n",
       "450  Released  The most astonishing, innovative, backyard adv...   \n",
       "423  Released                         Chucky has a new playmate.   \n",
       "23   Released                                                NaN   \n",
       "\n",
       "                          title  video  vote_average  vote_count  \\\n",
       "0                     Toy Story  False           7.7      5415.0   \n",
       "400              Small Soldiers  False           6.2       522.0   \n",
       "450    Honey, I Shrunk the Kids  False           6.1       756.0   \n",
       "423              Child's Play 3  False           5.5       274.0   \n",
       "23   The Indian in the Cupboard  False           5.9       136.0   \n",
       "\n",
       "                                                  cast  \\\n",
       "0    [Tom Hanks, Tim Allen, Don Rickles, Jim Varney...   \n",
       "400  [Gregory Smith, Kirsten Dunst, Denis Leary, Ph...   \n",
       "450  [Rick Moranis, Marcia Strassman, Matt Frewer, ...   \n",
       "423  [Justin Whalin, Perrey Reeves, Jeremy Sylvers,...   \n",
       "23   [Hal Scardino, Litefoot, Lindsay Crouse, Richa...   \n",
       "\n",
       "                                                  crew  \\\n",
       "0    [John Lasseter, Joss Whedon, Andrew Stanton, J...   \n",
       "400  [Ted Elliott, Terry Rossio, Denise Chamian, Co...   \n",
       "450  [James Horner, Hiro Narita, Tom Schulman, Joe ...   \n",
       "423  [John Frazier, John R. Leonetti, David Kirschn...   \n",
       "23   [Frank Oz, Kathleen Kennedy, Melissa Mathison,...   \n",
       "\n",
       "                                              keywords  \\\n",
       "0    [jealousy, toy, boy, friendship, friends, riva...   \n",
       "400  [defense industry, toy shop, technical toy, so...   \n",
       "450  [inventor, ant, shrinking, riesen insekten, bi...   \n",
       "423  [recruit, puppet, killer doll, serial killer, ...   \n",
       "23   [cupboard, games, puppet, parallel world, toy ...   \n",
       "\n",
       "                                textual_representation  \\\n",
       "0    [TITLE] Toy Story [TAGLINE] nan [OVERVIEW] Led...   \n",
       "400  [TITLE] Small Soldiers [TAGLINE] The few, the ...   \n",
       "450  [TITLE] Honey, I Shrunk the Kids [TAGLINE] The...   \n",
       "423  [TITLE] Child's Play 3 [TAGLINE] Chucky has a ...   \n",
       "23   [TITLE] The Indian in the Cupboard [TAGLINE] n...   \n",
       "\n",
       "                                                  plot  \n",
       "0    Here's a detailed summary of the plot of Toy S...  \n",
       "400  Here's a detailed plot summary of the movie Sm...  \n",
       "450  Here's a detailed plot summary of the movie \"H...  \n",
       "423  Here's a detailed plot summary of Child's Play...  \n",
       "23   Here's a detailed summary of the plot:\\n\\nThe ...  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['textual_representation'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(data['textual_representation'][0], return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
